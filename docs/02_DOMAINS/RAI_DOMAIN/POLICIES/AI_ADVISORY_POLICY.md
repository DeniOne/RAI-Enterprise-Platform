---
id: DOC-DOM-GEN-075
type: Domain Spec
layer: Domain
status: Draft
version: 0.1.0
owners: [@techlead]
last_updated: 2026-02-15
---

---
id: guideline-rai-ai-policy
type: guideline
status: review
owners: [domain-experts]
aligned_with: [principle-vision]
---

# AI Advisory Policy (Политика ИИ-советника) ⚖️

> **Статус:** Канон | **Версия:** 1.0 | **Слой:** RAI / Policies

---

## 1. Главный принцип
**AI Explains. Human Decides.**
ИИ в RAI Enterprise Platform не является автономным агентом, принимающим решения. Он является **интеллектуальным ассистентом**, который подсвечивает риски и предлагает варианты на основе данных.

---

## 2. Разграничение ответственности

### 2.1. ИИ-компонент (Система)
- Обязан предоставлять **аргументированные** рекомендации (со ссылкой на энграммы или техкарты).
- Обязан предупреждать о **негативных сценариях** (через алерты Negative Engrams).
- Обязан соблюдать строгую изоляцию данных (Multi-tenancy).

### 2.2. Пользователь (Человек)
- Несет полную ответственность за фактическое выполнение работ в поле.
- Имеет право отклонить любую рекомендацию ИИ без объяснения причин.
- Финализирует любое действие, имеющее экономические последствия (заказ семян, запуск обработки).

---

## 3. Запрещенные действия (Hard Constraints)
ИИ категорически **запрещено** без прямого подтверждения человека:
1. Удалять или изменять границы полей в `Registry`.
2. Изменять статусы Финансовых транзакций.
3. Отправлять распоряжения сторонним подрядчикам.
4. Изменять Ролевую модель (RBAC) пользователей.

---

## 4. Градация уведомлений
- **INFO**: Подсказки по оптимизации (например, "Можно снизить расход топлива на 5%").
- **WARNING**: Отклонение от плана (например, "Задержка посева на 2 дня").
- **CRITICAL**: Алерты на основе Negative Engrams (например, "Риск гибели урожая: влажность почвы критическая").

---

## 5. Этика и прозрачность
Любой ответ ИИ, который повлиял на решение, должен быть сохранен в `AuditLog` вместе с "уверенностью" (Confidence Score) модели на момент генерации.
